{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:This caffe2 python run does not have GPU support. Will run in CPU only mode.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# MNIST dataset \n",
    "dataset = torchvision.datasets.MNIST(root='../../data', \n",
    "                                     train=True, \n",
    "                                     transform=transforms.ToTensor(),  \n",
    "                                     download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=dataset, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size=784, hidden_size=500, num_classes=10):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "model = NeuralNet().to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00001)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(data_loader)\n",
    "iter_per_epoch = len(data_loader)\n",
    "total_step = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [100/50000], Loss: 2.2031, Acc: 0.25\n",
      "Step [200/50000], Loss: 2.0797, Acc: 0.55\n",
      "Step [300/50000], Loss: 1.9889, Acc: 0.68\n",
      "Step [400/50000], Loss: 1.8362, Acc: 0.80\n",
      "Step [500/50000], Loss: 1.6993, Acc: 0.76\n",
      "Step [600/50000], Loss: 1.6184, Acc: 0.74\n",
      "Step [700/50000], Loss: 1.4617, Acc: 0.83\n",
      "Step [800/50000], Loss: 1.3699, Acc: 0.77\n",
      "Step [900/50000], Loss: 1.2275, Acc: 0.84\n",
      "Step [1000/50000], Loss: 1.1499, Acc: 0.86\n",
      "Step [1100/50000], Loss: 1.1403, Acc: 0.82\n",
      "Step [1200/50000], Loss: 0.9357, Acc: 0.90\n",
      "Step [1300/50000], Loss: 0.8854, Acc: 0.90\n",
      "Step [1400/50000], Loss: 0.9040, Acc: 0.87\n",
      "Step [1500/50000], Loss: 0.9381, Acc: 0.82\n",
      "Step [1600/50000], Loss: 0.8487, Acc: 0.85\n",
      "Step [1700/50000], Loss: 0.7131, Acc: 0.88\n",
      "Step [1800/50000], Loss: 0.7206, Acc: 0.93\n",
      "Step [1900/50000], Loss: 0.7246, Acc: 0.84\n",
      "Step [2000/50000], Loss: 0.7244, Acc: 0.85\n",
      "Step [2100/50000], Loss: 0.6800, Acc: 0.89\n",
      "Step [2200/50000], Loss: 0.6570, Acc: 0.89\n",
      "Step [2300/50000], Loss: 0.6300, Acc: 0.87\n",
      "Step [2400/50000], Loss: 0.6444, Acc: 0.85\n",
      "Step [2500/50000], Loss: 0.7318, Acc: 0.81\n",
      "Step [2600/50000], Loss: 0.4507, Acc: 0.90\n",
      "Step [2700/50000], Loss: 0.5562, Acc: 0.88\n",
      "Step [2800/50000], Loss: 0.5841, Acc: 0.86\n",
      "Step [2900/50000], Loss: 0.5506, Acc: 0.89\n",
      "Step [3000/50000], Loss: 0.4077, Acc: 0.92\n",
      "Step [3100/50000], Loss: 0.3997, Acc: 0.94\n",
      "Step [3200/50000], Loss: 0.5646, Acc: 0.87\n",
      "Step [3300/50000], Loss: 0.5149, Acc: 0.86\n",
      "Step [3400/50000], Loss: 0.4081, Acc: 0.92\n",
      "Step [3500/50000], Loss: 0.6278, Acc: 0.81\n",
      "Step [3600/50000], Loss: 0.5098, Acc: 0.83\n",
      "Step [3700/50000], Loss: 0.4386, Acc: 0.89\n",
      "Step [3800/50000], Loss: 0.3905, Acc: 0.89\n",
      "Step [3900/50000], Loss: 0.4049, Acc: 0.93\n",
      "Step [4000/50000], Loss: 0.5498, Acc: 0.84\n",
      "Step [4100/50000], Loss: 0.3067, Acc: 0.93\n",
      "Step [4200/50000], Loss: 0.3200, Acc: 0.94\n",
      "Step [4300/50000], Loss: 0.5079, Acc: 0.88\n",
      "Step [4400/50000], Loss: 0.5350, Acc: 0.86\n",
      "Step [4500/50000], Loss: 0.2740, Acc: 0.90\n",
      "Step [4600/50000], Loss: 0.4396, Acc: 0.90\n",
      "Step [4700/50000], Loss: 0.4436, Acc: 0.89\n",
      "Step [4800/50000], Loss: 0.6233, Acc: 0.86\n",
      "Step [4900/50000], Loss: 0.5273, Acc: 0.84\n",
      "Step [5000/50000], Loss: 0.3533, Acc: 0.91\n",
      "Step [5100/50000], Loss: 0.3566, Acc: 0.90\n",
      "Step [5200/50000], Loss: 0.4263, Acc: 0.89\n",
      "Step [5300/50000], Loss: 0.3162, Acc: 0.94\n",
      "Step [5400/50000], Loss: 0.3308, Acc: 0.90\n",
      "Step [5500/50000], Loss: 0.3105, Acc: 0.91\n",
      "Step [5600/50000], Loss: 0.4053, Acc: 0.90\n",
      "Step [5700/50000], Loss: 0.4566, Acc: 0.90\n",
      "Step [5800/50000], Loss: 0.2524, Acc: 0.94\n",
      "Step [5900/50000], Loss: 0.2802, Acc: 0.93\n",
      "Step [6000/50000], Loss: 0.2593, Acc: 0.91\n",
      "Step [6100/50000], Loss: 0.4272, Acc: 0.91\n",
      "Step [6200/50000], Loss: 0.4463, Acc: 0.92\n",
      "Step [6300/50000], Loss: 0.4010, Acc: 0.88\n",
      "Step [6400/50000], Loss: 0.3258, Acc: 0.92\n",
      "Step [6500/50000], Loss: 0.2622, Acc: 0.92\n",
      "Step [6600/50000], Loss: 0.3313, Acc: 0.93\n",
      "Step [6700/50000], Loss: 0.4620, Acc: 0.84\n",
      "Step [6800/50000], Loss: 0.2072, Acc: 0.94\n",
      "Step [6900/50000], Loss: 0.4051, Acc: 0.87\n",
      "Step [7000/50000], Loss: 0.4258, Acc: 0.91\n",
      "Step [7100/50000], Loss: 0.2963, Acc: 0.95\n",
      "Step [7200/50000], Loss: 0.3485, Acc: 0.92\n",
      "Step [7300/50000], Loss: 0.2861, Acc: 0.92\n",
      "Step [7400/50000], Loss: 0.2387, Acc: 0.95\n",
      "Step [7500/50000], Loss: 0.3075, Acc: 0.92\n",
      "Step [7600/50000], Loss: 0.2532, Acc: 0.93\n",
      "Step [7700/50000], Loss: 0.2715, Acc: 0.93\n",
      "Step [7800/50000], Loss: 0.3442, Acc: 0.91\n",
      "Step [7900/50000], Loss: 0.2631, Acc: 0.93\n",
      "Step [8000/50000], Loss: 0.2570, Acc: 0.95\n",
      "Step [8100/50000], Loss: 0.2391, Acc: 0.92\n",
      "Step [8200/50000], Loss: 0.5542, Acc: 0.86\n",
      "Step [8300/50000], Loss: 0.2909, Acc: 0.93\n",
      "Step [8400/50000], Loss: 0.2570, Acc: 0.92\n",
      "Step [8500/50000], Loss: 0.2848, Acc: 0.88\n",
      "Step [8600/50000], Loss: 0.2875, Acc: 0.93\n",
      "Step [8700/50000], Loss: 0.3348, Acc: 0.92\n",
      "Step [8800/50000], Loss: 0.3721, Acc: 0.88\n",
      "Step [8900/50000], Loss: 0.3000, Acc: 0.91\n",
      "Step [9000/50000], Loss: 0.3753, Acc: 0.89\n",
      "Step [9100/50000], Loss: 0.2666, Acc: 0.92\n",
      "Step [9200/50000], Loss: 0.2431, Acc: 0.93\n",
      "Step [9300/50000], Loss: 0.2179, Acc: 0.95\n",
      "Step [9400/50000], Loss: 0.1913, Acc: 0.96\n",
      "Step [9500/50000], Loss: 0.2998, Acc: 0.91\n",
      "Step [9600/50000], Loss: 0.2387, Acc: 0.94\n",
      "Step [9700/50000], Loss: 0.2741, Acc: 0.92\n",
      "Step [9800/50000], Loss: 0.2958, Acc: 0.91\n",
      "Step [9900/50000], Loss: 0.3909, Acc: 0.89\n",
      "Step [10000/50000], Loss: 0.3140, Acc: 0.89\n",
      "Step [10100/50000], Loss: 0.2321, Acc: 0.93\n",
      "Step [10200/50000], Loss: 0.2662, Acc: 0.92\n",
      "Step [10300/50000], Loss: 0.2367, Acc: 0.91\n",
      "Step [10400/50000], Loss: 0.4080, Acc: 0.90\n",
      "Step [10500/50000], Loss: 0.2763, Acc: 0.89\n",
      "Step [10600/50000], Loss: 0.3007, Acc: 0.93\n",
      "Step [10700/50000], Loss: 0.4130, Acc: 0.90\n",
      "Step [10800/50000], Loss: 0.2877, Acc: 0.92\n",
      "Step [10900/50000], Loss: 0.3302, Acc: 0.92\n",
      "Step [11000/50000], Loss: 0.2766, Acc: 0.93\n",
      "Step [11100/50000], Loss: 0.2542, Acc: 0.93\n",
      "Step [11200/50000], Loss: 0.3324, Acc: 0.91\n",
      "Step [11300/50000], Loss: 0.3620, Acc: 0.89\n",
      "Step [11400/50000], Loss: 0.2097, Acc: 0.94\n",
      "Step [11500/50000], Loss: 0.3753, Acc: 0.90\n",
      "Step [11600/50000], Loss: 0.2922, Acc: 0.93\n",
      "Step [11700/50000], Loss: 0.2895, Acc: 0.93\n",
      "Step [11800/50000], Loss: 0.2326, Acc: 0.94\n",
      "Step [11900/50000], Loss: 0.3279, Acc: 0.92\n",
      "Step [12000/50000], Loss: 0.3643, Acc: 0.90\n",
      "Step [12100/50000], Loss: 0.2130, Acc: 0.95\n",
      "Step [12200/50000], Loss: 0.2789, Acc: 0.94\n",
      "Step [12300/50000], Loss: 0.2307, Acc: 0.93\n",
      "Step [12400/50000], Loss: 0.1889, Acc: 0.94\n",
      "Step [12500/50000], Loss: 0.3499, Acc: 0.89\n",
      "Step [12600/50000], Loss: 0.2042, Acc: 0.95\n",
      "Step [12700/50000], Loss: 0.2845, Acc: 0.90\n",
      "Step [12800/50000], Loss: 0.2737, Acc: 0.93\n",
      "Step [12900/50000], Loss: 0.3370, Acc: 0.92\n",
      "Step [13000/50000], Loss: 0.1944, Acc: 0.95\n",
      "Step [13100/50000], Loss: 0.1960, Acc: 0.95\n",
      "Step [13200/50000], Loss: 0.3272, Acc: 0.90\n",
      "Step [13300/50000], Loss: 0.2544, Acc: 0.92\n",
      "Step [13400/50000], Loss: 0.2993, Acc: 0.92\n",
      "Step [13500/50000], Loss: 0.2912, Acc: 0.92\n",
      "Step [13600/50000], Loss: 0.2420, Acc: 0.91\n",
      "Step [13700/50000], Loss: 0.2766, Acc: 0.91\n",
      "Step [13800/50000], Loss: 0.2062, Acc: 0.95\n",
      "Step [13900/50000], Loss: 0.1686, Acc: 0.95\n",
      "Step [14000/50000], Loss: 0.2101, Acc: 0.96\n",
      "Step [14100/50000], Loss: 0.2070, Acc: 0.95\n",
      "Step [14200/50000], Loss: 0.2241, Acc: 0.94\n",
      "Step [14300/50000], Loss: 0.4600, Acc: 0.93\n",
      "Step [14400/50000], Loss: 0.2338, Acc: 0.93\n",
      "Step [14500/50000], Loss: 0.2933, Acc: 0.92\n",
      "Step [14600/50000], Loss: 0.1950, Acc: 0.97\n",
      "Step [14700/50000], Loss: 0.2869, Acc: 0.91\n",
      "Step [14800/50000], Loss: 0.2845, Acc: 0.93\n",
      "Step [14900/50000], Loss: 0.2357, Acc: 0.90\n",
      "Step [15000/50000], Loss: 0.2992, Acc: 0.90\n",
      "Step [15100/50000], Loss: 0.2331, Acc: 0.94\n",
      "Step [15200/50000], Loss: 0.2246, Acc: 0.93\n",
      "Step [15300/50000], Loss: 0.2020, Acc: 0.96\n",
      "Step [15400/50000], Loss: 0.2515, Acc: 0.94\n",
      "Step [15500/50000], Loss: 0.1944, Acc: 0.96\n",
      "Step [15600/50000], Loss: 0.2593, Acc: 0.96\n",
      "Step [15700/50000], Loss: 0.2570, Acc: 0.96\n",
      "Step [15800/50000], Loss: 0.1876, Acc: 0.95\n",
      "Step [15900/50000], Loss: 0.1965, Acc: 0.94\n",
      "Step [16000/50000], Loss: 0.3597, Acc: 0.89\n",
      "Step [16100/50000], Loss: 0.2035, Acc: 0.97\n",
      "Step [16200/50000], Loss: 0.2868, Acc: 0.91\n",
      "Step [16300/50000], Loss: 0.1920, Acc: 0.93\n",
      "Step [16400/50000], Loss: 0.1208, Acc: 0.97\n",
      "Step [16500/50000], Loss: 0.2994, Acc: 0.91\n",
      "Step [16600/50000], Loss: 0.2851, Acc: 0.93\n",
      "Step [16700/50000], Loss: 0.3829, Acc: 0.87\n",
      "Step [16800/50000], Loss: 0.2097, Acc: 0.95\n",
      "Step [16900/50000], Loss: 0.3272, Acc: 0.93\n",
      "Step [17000/50000], Loss: 0.1906, Acc: 0.94\n",
      "Step [17100/50000], Loss: 0.1520, Acc: 0.96\n",
      "Step [17200/50000], Loss: 0.1948, Acc: 0.95\n",
      "Step [17300/50000], Loss: 0.2641, Acc: 0.91\n",
      "Step [17400/50000], Loss: 0.1809, Acc: 0.94\n",
      "Step [17500/50000], Loss: 0.2286, Acc: 0.95\n",
      "Step [17600/50000], Loss: 0.2208, Acc: 0.95\n",
      "Step [17700/50000], Loss: 0.3188, Acc: 0.90\n",
      "Step [17800/50000], Loss: 0.2963, Acc: 0.94\n",
      "Step [17900/50000], Loss: 0.3746, Acc: 0.90\n",
      "Step [18000/50000], Loss: 0.1615, Acc: 0.97\n",
      "Step [18100/50000], Loss: 0.1967, Acc: 0.92\n",
      "Step [18200/50000], Loss: 0.1765, Acc: 0.96\n",
      "Step [18300/50000], Loss: 0.1745, Acc: 0.96\n",
      "Step [18400/50000], Loss: 0.2568, Acc: 0.91\n",
      "Step [18500/50000], Loss: 0.3289, Acc: 0.91\n",
      "Step [18600/50000], Loss: 0.1603, Acc: 0.96\n",
      "Step [18700/50000], Loss: 0.2468, Acc: 0.91\n",
      "Step [18800/50000], Loss: 0.3400, Acc: 0.88\n",
      "Step [18900/50000], Loss: 0.3277, Acc: 0.92\n",
      "Step [19000/50000], Loss: 0.2885, Acc: 0.91\n",
      "Step [19100/50000], Loss: 0.2187, Acc: 0.95\n",
      "Step [19200/50000], Loss: 0.2342, Acc: 0.95\n",
      "Step [19300/50000], Loss: 0.1654, Acc: 0.95\n",
      "Step [19400/50000], Loss: 0.1827, Acc: 0.96\n",
      "Step [19500/50000], Loss: 0.2671, Acc: 0.91\n",
      "Step [19600/50000], Loss: 0.1124, Acc: 0.98\n",
      "Step [19700/50000], Loss: 0.3000, Acc: 0.93\n",
      "Step [19800/50000], Loss: 0.2764, Acc: 0.89\n",
      "Step [19900/50000], Loss: 0.2829, Acc: 0.92\n",
      "Step [20000/50000], Loss: 0.1790, Acc: 0.95\n",
      "Step [20100/50000], Loss: 0.1974, Acc: 0.95\n",
      "Step [20200/50000], Loss: 0.1629, Acc: 0.97\n",
      "Step [20300/50000], Loss: 0.2141, Acc: 0.96\n",
      "Step [20400/50000], Loss: 0.2039, Acc: 0.94\n",
      "Step [20500/50000], Loss: 0.2101, Acc: 0.93\n",
      "Step [20600/50000], Loss: 0.1367, Acc: 0.94\n",
      "Step [20700/50000], Loss: 0.3849, Acc: 0.94\n",
      "Step [20800/50000], Loss: 0.2445, Acc: 0.92\n",
      "Step [20900/50000], Loss: 0.2520, Acc: 0.94\n",
      "Step [21000/50000], Loss: 0.3036, Acc: 0.95\n",
      "Step [21100/50000], Loss: 0.1612, Acc: 0.95\n",
      "Step [21200/50000], Loss: 0.2273, Acc: 0.91\n",
      "Step [21300/50000], Loss: 0.2801, Acc: 0.90\n",
      "Step [21400/50000], Loss: 0.2369, Acc: 0.93\n",
      "Step [21500/50000], Loss: 0.1841, Acc: 0.97\n",
      "Step [21600/50000], Loss: 0.1874, Acc: 0.95\n",
      "Step [21700/50000], Loss: 0.2534, Acc: 0.93\n",
      "Step [21800/50000], Loss: 0.4400, Acc: 0.86\n",
      "Step [21900/50000], Loss: 0.1769, Acc: 0.95\n",
      "Step [22000/50000], Loss: 0.2993, Acc: 0.92\n",
      "Step [22100/50000], Loss: 0.2387, Acc: 0.94\n",
      "Step [22200/50000], Loss: 0.2491, Acc: 0.94\n",
      "Step [22300/50000], Loss: 0.1956, Acc: 0.96\n",
      "Step [22400/50000], Loss: 0.1588, Acc: 0.96\n",
      "Step [22500/50000], Loss: 0.2191, Acc: 0.91\n",
      "Step [22600/50000], Loss: 0.2722, Acc: 0.90\n",
      "Step [22700/50000], Loss: 0.2321, Acc: 0.94\n",
      "Step [22800/50000], Loss: 0.2570, Acc: 0.91\n",
      "Step [22900/50000], Loss: 0.1303, Acc: 0.97\n",
      "Step [23000/50000], Loss: 0.1390, Acc: 0.97\n",
      "Step [23100/50000], Loss: 0.2512, Acc: 0.94\n",
      "Step [23200/50000], Loss: 0.2254, Acc: 0.94\n",
      "Step [23300/50000], Loss: 0.1387, Acc: 0.96\n",
      "Step [23400/50000], Loss: 0.1411, Acc: 0.98\n",
      "Step [23500/50000], Loss: 0.3722, Acc: 0.90\n",
      "Step [23600/50000], Loss: 0.3201, Acc: 0.89\n",
      "Step [23700/50000], Loss: 0.0797, Acc: 1.00\n",
      "Step [23800/50000], Loss: 0.1793, Acc: 0.96\n",
      "Step [23900/50000], Loss: 0.1883, Acc: 0.93\n",
      "Step [24000/50000], Loss: 0.1637, Acc: 0.98\n",
      "Step [24100/50000], Loss: 0.1927, Acc: 0.93\n",
      "Step [24200/50000], Loss: 0.2595, Acc: 0.91\n",
      "Step [24300/50000], Loss: 0.3850, Acc: 0.87\n",
      "Step [24400/50000], Loss: 0.1474, Acc: 0.97\n",
      "Step [24500/50000], Loss: 0.4542, Acc: 0.89\n",
      "Step [24600/50000], Loss: 0.1792, Acc: 0.95\n",
      "Step [24700/50000], Loss: 0.1957, Acc: 0.94\n",
      "Step [24800/50000], Loss: 0.2818, Acc: 0.92\n",
      "Step [24900/50000], Loss: 0.2309, Acc: 0.92\n",
      "Step [25000/50000], Loss: 0.2801, Acc: 0.92\n",
      "Step [25100/50000], Loss: 0.1815, Acc: 0.97\n",
      "Step [25200/50000], Loss: 0.1829, Acc: 0.94\n",
      "Step [25300/50000], Loss: 0.1974, Acc: 0.94\n",
      "Step [25400/50000], Loss: 0.2003, Acc: 0.94\n",
      "Step [25500/50000], Loss: 0.1493, Acc: 0.96\n",
      "Step [25600/50000], Loss: 0.1299, Acc: 0.99\n",
      "Step [25700/50000], Loss: 0.1445, Acc: 0.96\n",
      "Step [25800/50000], Loss: 0.1897, Acc: 0.94\n",
      "Step [25900/50000], Loss: 0.2528, Acc: 0.90\n",
      "Step [26000/50000], Loss: 0.1945, Acc: 0.94\n",
      "Step [26100/50000], Loss: 0.2182, Acc: 0.94\n",
      "Step [26200/50000], Loss: 0.2259, Acc: 0.94\n",
      "Step [26300/50000], Loss: 0.2166, Acc: 0.93\n",
      "Step [26400/50000], Loss: 0.2737, Acc: 0.91\n",
      "Step [26500/50000], Loss: 0.1952, Acc: 0.93\n",
      "Step [26600/50000], Loss: 0.1767, Acc: 0.96\n",
      "Step [26700/50000], Loss: 0.1102, Acc: 0.98\n",
      "Step [26800/50000], Loss: 0.1730, Acc: 0.95\n",
      "Step [26900/50000], Loss: 0.1811, Acc: 0.95\n",
      "Step [27000/50000], Loss: 0.1722, Acc: 0.94\n",
      "Step [27100/50000], Loss: 0.2109, Acc: 0.96\n",
      "Step [27200/50000], Loss: 0.2590, Acc: 0.93\n",
      "Step [27300/50000], Loss: 0.1494, Acc: 0.94\n",
      "Step [27400/50000], Loss: 0.2425, Acc: 0.93\n",
      "Step [27500/50000], Loss: 0.0818, Acc: 0.98\n",
      "Step [27600/50000], Loss: 0.1127, Acc: 0.96\n",
      "Step [27700/50000], Loss: 0.1895, Acc: 0.94\n",
      "Step [27800/50000], Loss: 0.1764, Acc: 0.94\n",
      "Step [27900/50000], Loss: 0.1357, Acc: 0.96\n",
      "Step [28000/50000], Loss: 0.1862, Acc: 0.94\n",
      "Step [28100/50000], Loss: 0.2022, Acc: 0.93\n",
      "Step [28200/50000], Loss: 0.0964, Acc: 0.98\n",
      "Step [28300/50000], Loss: 0.3021, Acc: 0.93\n",
      "Step [28400/50000], Loss: 0.1508, Acc: 0.94\n",
      "Step [28500/50000], Loss: 0.1430, Acc: 0.95\n",
      "Step [28600/50000], Loss: 0.2124, Acc: 0.91\n",
      "Step [28700/50000], Loss: 0.1701, Acc: 0.94\n",
      "Step [28800/50000], Loss: 0.2592, Acc: 0.92\n",
      "Step [28900/50000], Loss: 0.1718, Acc: 0.95\n",
      "Step [29000/50000], Loss: 0.1221, Acc: 0.98\n",
      "Step [29100/50000], Loss: 0.2748, Acc: 0.92\n",
      "Step [29200/50000], Loss: 0.1836, Acc: 0.95\n",
      "Step [29300/50000], Loss: 0.1207, Acc: 0.97\n",
      "Step [29400/50000], Loss: 0.1628, Acc: 0.96\n",
      "Step [29500/50000], Loss: 0.2202, Acc: 0.92\n",
      "Step [29600/50000], Loss: 0.0947, Acc: 0.98\n",
      "Step [29700/50000], Loss: 0.2079, Acc: 0.94\n",
      "Step [29800/50000], Loss: 0.1452, Acc: 0.98\n",
      "Step [29900/50000], Loss: 0.1526, Acc: 0.95\n",
      "Step [30000/50000], Loss: 0.2482, Acc: 0.95\n",
      "Step [30100/50000], Loss: 0.2225, Acc: 0.92\n",
      "Step [30200/50000], Loss: 0.1124, Acc: 0.96\n",
      "Step [30300/50000], Loss: 0.2601, Acc: 0.91\n",
      "Step [30400/50000], Loss: 0.2327, Acc: 0.94\n",
      "Step [30500/50000], Loss: 0.0811, Acc: 0.98\n",
      "Step [30600/50000], Loss: 0.1894, Acc: 0.93\n",
      "Step [30700/50000], Loss: 0.2571, Acc: 0.91\n",
      "Step [30800/50000], Loss: 0.1892, Acc: 0.94\n",
      "Step [30900/50000], Loss: 0.1273, Acc: 0.97\n",
      "Step [31000/50000], Loss: 0.1734, Acc: 0.95\n",
      "Step [31100/50000], Loss: 0.2078, Acc: 0.93\n",
      "Step [31200/50000], Loss: 0.1205, Acc: 0.98\n",
      "Step [31300/50000], Loss: 0.1482, Acc: 0.97\n",
      "Step [31400/50000], Loss: 0.1187, Acc: 0.95\n",
      "Step [31500/50000], Loss: 0.1050, Acc: 0.98\n",
      "Step [31600/50000], Loss: 0.1464, Acc: 0.97\n",
      "Step [31700/50000], Loss: 0.2656, Acc: 0.93\n",
      "Step [31800/50000], Loss: 0.2336, Acc: 0.93\n",
      "Step [31900/50000], Loss: 0.1692, Acc: 0.97\n",
      "Step [32000/50000], Loss: 0.1938, Acc: 0.94\n",
      "Step [32100/50000], Loss: 0.1663, Acc: 0.95\n",
      "Step [32200/50000], Loss: 0.1343, Acc: 0.94\n",
      "Step [32300/50000], Loss: 0.2175, Acc: 0.96\n",
      "Step [32400/50000], Loss: 0.2549, Acc: 0.94\n",
      "Step [32500/50000], Loss: 0.1122, Acc: 0.97\n",
      "Step [32600/50000], Loss: 0.2086, Acc: 0.93\n",
      "Step [32700/50000], Loss: 0.1327, Acc: 0.97\n",
      "Step [32800/50000], Loss: 0.1951, Acc: 0.95\n",
      "Step [32900/50000], Loss: 0.1063, Acc: 0.97\n",
      "Step [33000/50000], Loss: 0.1161, Acc: 0.96\n",
      "Step [33100/50000], Loss: 0.1303, Acc: 0.96\n",
      "Step [33200/50000], Loss: 0.1589, Acc: 0.95\n",
      "Step [33300/50000], Loss: 0.2576, Acc: 0.93\n",
      "Step [33400/50000], Loss: 0.1127, Acc: 0.96\n",
      "Step [33500/50000], Loss: 0.1588, Acc: 0.96\n",
      "Step [33600/50000], Loss: 0.1494, Acc: 0.98\n",
      "Step [33700/50000], Loss: 0.1980, Acc: 0.97\n",
      "Step [33800/50000], Loss: 0.0712, Acc: 1.00\n",
      "Step [33900/50000], Loss: 0.2357, Acc: 0.95\n",
      "Step [34000/50000], Loss: 0.1691, Acc: 0.94\n",
      "Step [34100/50000], Loss: 0.1588, Acc: 0.96\n",
      "Step [34200/50000], Loss: 0.2493, Acc: 0.95\n",
      "Step [34300/50000], Loss: 0.1479, Acc: 0.95\n",
      "Step [34400/50000], Loss: 0.0926, Acc: 0.97\n",
      "Step [34500/50000], Loss: 0.2153, Acc: 0.95\n",
      "Step [34600/50000], Loss: 0.2436, Acc: 0.93\n",
      "Step [34700/50000], Loss: 0.1499, Acc: 0.96\n",
      "Step [34800/50000], Loss: 0.1994, Acc: 0.95\n",
      "Step [34900/50000], Loss: 0.1791, Acc: 0.94\n",
      "Step [35000/50000], Loss: 0.1895, Acc: 0.92\n",
      "Step [35100/50000], Loss: 0.1414, Acc: 0.96\n",
      "Step [35200/50000], Loss: 0.2223, Acc: 0.95\n",
      "Step [35300/50000], Loss: 0.1551, Acc: 0.96\n",
      "Step [35400/50000], Loss: 0.1313, Acc: 0.96\n",
      "Step [35500/50000], Loss: 0.2895, Acc: 0.92\n",
      "Step [35600/50000], Loss: 0.1510, Acc: 0.95\n",
      "Step [35700/50000], Loss: 0.1660, Acc: 0.95\n",
      "Step [35800/50000], Loss: 0.1065, Acc: 0.97\n",
      "Step [35900/50000], Loss: 0.1572, Acc: 0.96\n",
      "Step [36000/50000], Loss: 0.1010, Acc: 0.97\n",
      "Step [36100/50000], Loss: 0.1973, Acc: 0.95\n",
      "Step [36200/50000], Loss: 0.2483, Acc: 0.93\n",
      "Step [36300/50000], Loss: 0.0680, Acc: 0.98\n",
      "Step [36400/50000], Loss: 0.1741, Acc: 0.95\n",
      "Step [36500/50000], Loss: 0.1752, Acc: 0.96\n",
      "Step [36600/50000], Loss: 0.1845, Acc: 0.93\n",
      "Step [36700/50000], Loss: 0.2622, Acc: 0.94\n",
      "Step [36800/50000], Loss: 0.1602, Acc: 0.96\n",
      "Step [36900/50000], Loss: 0.2304, Acc: 0.93\n",
      "Step [37000/50000], Loss: 0.1887, Acc: 0.97\n",
      "Step [37100/50000], Loss: 0.2062, Acc: 0.92\n",
      "Step [37200/50000], Loss: 0.1437, Acc: 0.96\n",
      "Step [37300/50000], Loss: 0.1666, Acc: 0.95\n",
      "Step [37400/50000], Loss: 0.2175, Acc: 0.93\n",
      "Step [37500/50000], Loss: 0.2097, Acc: 0.93\n",
      "Step [37600/50000], Loss: 0.2208, Acc: 0.96\n",
      "Step [37700/50000], Loss: 0.1846, Acc: 0.95\n",
      "Step [37800/50000], Loss: 0.1872, Acc: 0.93\n",
      "Step [37900/50000], Loss: 0.1592, Acc: 0.97\n",
      "Step [38000/50000], Loss: 0.2013, Acc: 0.95\n",
      "Step [38100/50000], Loss: 0.2916, Acc: 0.94\n",
      "Step [38200/50000], Loss: 0.1227, Acc: 0.96\n",
      "Step [38300/50000], Loss: 0.2775, Acc: 0.91\n",
      "Step [38400/50000], Loss: 0.2142, Acc: 0.94\n",
      "Step [38500/50000], Loss: 0.1445, Acc: 0.96\n",
      "Step [38600/50000], Loss: 0.1517, Acc: 0.95\n",
      "Step [38700/50000], Loss: 0.0837, Acc: 0.98\n",
      "Step [38800/50000], Loss: 0.1362, Acc: 0.94\n",
      "Step [38900/50000], Loss: 0.1168, Acc: 0.95\n",
      "Step [39000/50000], Loss: 0.2157, Acc: 0.92\n",
      "Step [39100/50000], Loss: 0.2736, Acc: 0.92\n",
      "Step [39200/50000], Loss: 0.0696, Acc: 1.00\n",
      "Step [39300/50000], Loss: 0.1135, Acc: 0.96\n",
      "Step [39400/50000], Loss: 0.1901, Acc: 0.92\n",
      "Step [39500/50000], Loss: 0.1277, Acc: 0.96\n",
      "Step [39600/50000], Loss: 0.1227, Acc: 0.97\n",
      "Step [39700/50000], Loss: 0.1400, Acc: 0.97\n",
      "Step [39800/50000], Loss: 0.1267, Acc: 0.96\n",
      "Step [39900/50000], Loss: 0.1628, Acc: 0.94\n",
      "Step [40000/50000], Loss: 0.1517, Acc: 0.94\n",
      "Step [40100/50000], Loss: 0.1620, Acc: 0.97\n",
      "Step [40200/50000], Loss: 0.1897, Acc: 0.95\n",
      "Step [40300/50000], Loss: 0.1526, Acc: 0.96\n",
      "Step [40400/50000], Loss: 0.1338, Acc: 0.95\n",
      "Step [40500/50000], Loss: 0.1822, Acc: 0.95\n",
      "Step [40600/50000], Loss: 0.2496, Acc: 0.93\n",
      "Step [40700/50000], Loss: 0.1279, Acc: 0.95\n",
      "Step [40800/50000], Loss: 0.2090, Acc: 0.92\n",
      "Step [40900/50000], Loss: 0.1085, Acc: 0.96\n",
      "Step [41000/50000], Loss: 0.1055, Acc: 0.98\n",
      "Step [41100/50000], Loss: 0.1338, Acc: 0.97\n",
      "Step [41200/50000], Loss: 0.1561, Acc: 0.94\n",
      "Step [41300/50000], Loss: 0.1533, Acc: 0.94\n",
      "Step [41400/50000], Loss: 0.2262, Acc: 0.92\n",
      "Step [41500/50000], Loss: 0.2573, Acc: 0.92\n",
      "Step [41600/50000], Loss: 0.1205, Acc: 0.96\n",
      "Step [41700/50000], Loss: 0.1173, Acc: 0.97\n",
      "Step [41800/50000], Loss: 0.1101, Acc: 0.97\n",
      "Step [41900/50000], Loss: 0.1474, Acc: 0.97\n",
      "Step [42000/50000], Loss: 0.2463, Acc: 0.92\n",
      "Step [42100/50000], Loss: 0.1301, Acc: 0.95\n",
      "Step [42200/50000], Loss: 0.0952, Acc: 0.98\n",
      "Step [42300/50000], Loss: 0.0899, Acc: 0.98\n",
      "Step [42400/50000], Loss: 0.1829, Acc: 0.96\n",
      "Step [42500/50000], Loss: 0.1504, Acc: 0.95\n",
      "Step [42600/50000], Loss: 0.1828, Acc: 0.96\n",
      "Step [42700/50000], Loss: 0.1558, Acc: 0.93\n",
      "Step [42800/50000], Loss: 0.1931, Acc: 0.95\n",
      "Step [42900/50000], Loss: 0.1261, Acc: 0.94\n",
      "Step [43000/50000], Loss: 0.1676, Acc: 0.96\n",
      "Step [43100/50000], Loss: 0.1582, Acc: 0.97\n",
      "Step [43200/50000], Loss: 0.0889, Acc: 0.98\n",
      "Step [43300/50000], Loss: 0.1290, Acc: 0.97\n",
      "Step [43400/50000], Loss: 0.0767, Acc: 1.00\n",
      "Step [43500/50000], Loss: 0.1183, Acc: 0.97\n",
      "Step [43600/50000], Loss: 0.2123, Acc: 0.93\n",
      "Step [43700/50000], Loss: 0.0863, Acc: 0.99\n",
      "Step [43800/50000], Loss: 0.1602, Acc: 0.96\n",
      "Step [43900/50000], Loss: 0.1191, Acc: 0.95\n",
      "Step [44000/50000], Loss: 0.0958, Acc: 0.97\n",
      "Step [44100/50000], Loss: 0.1093, Acc: 0.96\n",
      "Step [44200/50000], Loss: 0.2279, Acc: 0.94\n",
      "Step [44300/50000], Loss: 0.1567, Acc: 0.95\n",
      "Step [44400/50000], Loss: 0.0889, Acc: 0.99\n",
      "Step [44500/50000], Loss: 0.1101, Acc: 0.98\n",
      "Step [44600/50000], Loss: 0.1166, Acc: 0.97\n",
      "Step [44700/50000], Loss: 0.1499, Acc: 0.94\n",
      "Step [44800/50000], Loss: 0.0418, Acc: 1.00\n",
      "Step [44900/50000], Loss: 0.1498, Acc: 0.97\n",
      "Step [45000/50000], Loss: 0.2188, Acc: 0.93\n",
      "Step [45100/50000], Loss: 0.1243, Acc: 0.96\n",
      "Step [45200/50000], Loss: 0.0635, Acc: 0.98\n",
      "Step [45300/50000], Loss: 0.1365, Acc: 0.96\n",
      "Step [45400/50000], Loss: 0.1537, Acc: 0.97\n",
      "Step [45500/50000], Loss: 0.1754, Acc: 0.96\n",
      "Step [45600/50000], Loss: 0.1448, Acc: 0.94\n",
      "Step [45700/50000], Loss: 0.1530, Acc: 0.96\n",
      "Step [45800/50000], Loss: 0.1365, Acc: 0.97\n",
      "Step [45900/50000], Loss: 0.0806, Acc: 0.99\n",
      "Step [46000/50000], Loss: 0.0874, Acc: 0.98\n",
      "Step [46100/50000], Loss: 0.0499, Acc: 0.99\n",
      "Step [46200/50000], Loss: 0.1198, Acc: 0.96\n",
      "Step [46300/50000], Loss: 0.2633, Acc: 0.95\n",
      "Step [46400/50000], Loss: 0.1107, Acc: 0.96\n",
      "Step [46500/50000], Loss: 0.0998, Acc: 0.97\n",
      "Step [46600/50000], Loss: 0.0794, Acc: 0.99\n",
      "Step [46700/50000], Loss: 0.2526, Acc: 0.93\n",
      "Step [46800/50000], Loss: 0.1465, Acc: 0.95\n",
      "Step [46900/50000], Loss: 0.1405, Acc: 0.96\n",
      "Step [47000/50000], Loss: 0.0857, Acc: 0.97\n",
      "Step [47100/50000], Loss: 0.1502, Acc: 0.96\n",
      "Step [47200/50000], Loss: 0.2454, Acc: 0.95\n",
      "Step [47300/50000], Loss: 0.1991, Acc: 0.96\n",
      "Step [47400/50000], Loss: 0.1451, Acc: 0.96\n",
      "Step [47500/50000], Loss: 0.1478, Acc: 0.96\n",
      "Step [47600/50000], Loss: 0.1029, Acc: 0.97\n",
      "Step [47700/50000], Loss: 0.1249, Acc: 0.94\n",
      "Step [47800/50000], Loss: 0.0740, Acc: 0.96\n",
      "Step [47900/50000], Loss: 0.1520, Acc: 0.95\n",
      "Step [48000/50000], Loss: 0.0940, Acc: 0.97\n",
      "Step [48100/50000], Loss: 0.2040, Acc: 0.94\n",
      "Step [48200/50000], Loss: 0.1081, Acc: 0.96\n",
      "Step [48300/50000], Loss: 0.0894, Acc: 0.99\n",
      "Step [48400/50000], Loss: 0.1369, Acc: 0.96\n",
      "Step [48500/50000], Loss: 0.0744, Acc: 0.98\n",
      "Step [48600/50000], Loss: 0.1277, Acc: 0.96\n",
      "Step [48700/50000], Loss: 0.1745, Acc: 0.95\n",
      "Step [48800/50000], Loss: 0.1374, Acc: 0.96\n",
      "Step [48900/50000], Loss: 0.1518, Acc: 0.96\n",
      "Step [49000/50000], Loss: 0.1584, Acc: 0.96\n",
      "Step [49100/50000], Loss: 0.1694, Acc: 0.96\n",
      "Step [49200/50000], Loss: 0.1601, Acc: 0.95\n",
      "Step [49300/50000], Loss: 0.1082, Acc: 0.98\n",
      "Step [49400/50000], Loss: 0.0637, Acc: 0.99\n",
      "Step [49500/50000], Loss: 0.0815, Acc: 0.98\n",
      "Step [49600/50000], Loss: 0.0989, Acc: 0.98\n",
      "Step [49700/50000], Loss: 0.1483, Acc: 0.97\n",
      "Step [49800/50000], Loss: 0.1734, Acc: 0.94\n",
      "Step [49900/50000], Loss: 0.1159, Acc: 0.98\n",
      "Step [50000/50000], Loss: 0.1061, Acc: 0.96\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "for step in range(total_step):\n",
    "    \n",
    "    # Reset the data_iter\n",
    "    if (step+1) % iter_per_epoch == 0:\n",
    "        data_iter = iter(data_loader)\n",
    "\n",
    "    # Fetch images and labels\n",
    "    images, labels = next(data_iter)\n",
    "    images, labels = images.view(images.size(0), -1).to(device), labels.to(device)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward and optimize\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Compute accuracy\n",
    "    _, argmax = torch.max(outputs, 1)\n",
    "    accuracy = (labels == argmax.squeeze()).float().mean()\n",
    "\n",
    "    if (step+1) % 100 == 0:\n",
    "        print ('Step [{}/{}], Loss: {:.4f}, Acc: {:.2f}' \n",
    "               .format(step+1, total_step, loss.item(), accuracy.item()))\n",
    "\n",
    "        # ================================================================== #\n",
    "        #                        Tensorboard Logging                         #\n",
    "        # ================================================================== #\n",
    "\n",
    "        # 1. Log scalar values (scalar summary)\n",
    "        info = { 'loss': loss.item(), 'accuracy': accuracy.item() }\n",
    "\n",
    "        for tag, value in info.items():\n",
    "            writer.add_scalar(tag, value, step+1)\n",
    "\n",
    "        # 2. Log values and gradients of the parameters (histogram summary)\n",
    "        for tag, value in model.named_parameters():\n",
    "            tag = tag.replace('.', '/')\n",
    "            writer.add_histogram(tag, value.data.cpu().numpy(), step+1)\n",
    "            writer.add_histogram(tag+'/grad', value.grad.data.cpu().numpy(), step+1)\n",
    "\n",
    "        # 3. Log training images (image summary)\n",
    "        info = { 'images': images.view(-1, 1, 28, 28)[:10].cpu() }\n",
    "\n",
    "        for tag, images in info.items():\n",
    "            grid = torchvision.utils.make_grid(images)\n",
    "            writer.add_image(tag, grid, step+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
